{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/skillfactorylogo.png\"></center>\n",
    "\n",
    "<h1><center>Курс \"Практический Machine Learning\"</center></h1>\n",
    "<h3><center>Шестаков Андрей</center></h3>\n",
    "<hr>\n",
    "<h2><center>Деревья решений</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (18,12)\n",
    "\n",
    "from ipywidgets import interact, IntSlider, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Пример 1 - алгоритм принятния решений\n",
    "\n",
    "* Вы приходите в банк за кредитом ~~не дай бог~~, подаете анкету со всеми необходимыми документами\n",
    "* Сотрудник банка проверяет вашу анкету:\n",
    "    1. Если объем сбережений <= 200 тыс., то перейти к шагу 2, иначе - к шагу 3.\n",
    "    2. Если стаж больше года - дать кредит, иначе - не давать\n",
    "    3. Если продолжительность займа < 30 месяцев - не давать кредит, иначе - к шагу 4\n",
    "    4. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='https://www.mapr.com/sites/default/files/blogimages/creditdecisiontree.png'><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример 2 - Играть или не играть?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='https://i.stack.imgur.com/KYSy4.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/Decision_tree_model.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример 3 - описание сегментов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='https://static01.nyt.com/images/2008/04/16/us/0416-nat-subOBAMA.jpg'><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формально, дерево решений - это связный ациклический граф. В нем можно выделить 3 типа вершин:\n",
    "1. Корневая вершина (root node) -  откуда все начинается\n",
    "2. Внутренние вершины (intermediate nodes)\n",
    "3. Листья (leafs) - самые глубокие вершины дерева, в которых содержится \"ответ\"\n",
    "\n",
    "Во внутренней или коневой вершине признак проверяется на некий логический критерий, по результатам которого мы движемся все глубже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Как определяются лучшие разбиения (best splits)?\n",
    "### Меры неопределенности (impurity measures)\n",
    "\n",
    "По какому мешку лучше классифицировать?\n",
    "\n",
    "<center><img src='img\\bins.png'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Как определяются лучшие разбиения (best splits)?\n",
    "### Меры неопределенности (impurity measures)\n",
    "\n",
    "Пусть $p_k$ - это доля класса $C_k$ в узле дерева $S$.\n",
    "\n",
    "1. Missclassification error  \n",
    "$$I(S) = 1 - \\max\\limits_k p_k $$\n",
    "2. Gini index \n",
    "$$I(S) = 1 - \\sum\\limits_k (p_k)^2 = \\sum\\limits_{k'\\neq k} p_{k'} p_k$$\n",
    "3. Entropy \n",
    "$$I(S) = -\\sum\\limits_k p_k \\log(p_k)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def plot_impurities():\n",
    "    p = np.linspace(0, 1, 100)\n",
    "    p = np.c_[p, 1-p]\n",
    "\n",
    "    missclass = 1 - p.max(axis=1)\n",
    "    plt.plot(p[:,0], missclass, label = 'missclassification error')\n",
    "\n",
    "    gini = 1 - (p ** 2).sum(axis=1)\n",
    "    plt.plot(p[:,0], gini, label = 'gini index')\n",
    "\n",
    "    entropy = - np.nansum((p*np.log2(p)), axis=1)\n",
    "    plt.plot(p[:,0], entropy, label = 'entropy')\n",
    "\n",
    "    plt.xlabel('$p_k$')\n",
    "    plt.ylabel('$I(S)$')\n",
    "    # plt.legend(loc=2, bbox_to_anchor=(0.,0.))\n",
    "    plt.legend(loc=2, bbox_to_anchor=(-0.3,1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_impurities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Как определяются лучшие разбиения (best splits)?\n",
    "### Прирост информации\n",
    "\n",
    "Выберем признак $A$ и пороговое значение $t$ на нем таким образом, чтобы уменьшить неопределенность:\n",
    "\n",
    "**Насколько уменьшится неопределенность:** <br/>\n",
    "$$ Gain(S, A) = I(S) - \\left(\\frac{|S_L|}{|S|}\\cdot I(S_L) + \\frac{|S_R|}{|S|}\\cdot I(S_R) \\right),$$ где $S_R$ и $S_L$ - это потомки узла $S$ c объектами, удовлетворяющим соответствующим условиям.\n",
    "\n",
    "* Стратегия выбора - жадная\n",
    "* Как определяется порог при вещественных признаках?\n",
    "* Локальная оптимизация - уменьшение Impurity внутри узла\n",
    "* Результаты не сильно зависят от выбора самой меры неопределенности\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def gini_impurity(p):\n",
    "    return 1 - (p**2).sum()\n",
    "\n",
    "def wine_demo():\n",
    "\n",
    "    df_wine = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    df_wine.loc[:, 'quality_cat'] = (df_wine.loc[:, 'quality'] > 5).astype(int) \n",
    "    idx = df_wine.loc[:, 'quality_cat'] == 1\n",
    "    df_wine.loc[idx, 'alcohol'].hist(label='good quality', bins=20, alpha = 0.4, ax=ax[0])\n",
    "    df_wine.loc[~idx, 'alcohol'].hist(label='bad quality', bins=20, alpha = 0.4, ax=ax[0])\n",
    "    ax[0].set_xlabel('alcohol')\n",
    "\n",
    "    p = np.array([df_wine.quality_cat.mean(), 1-df_wine.quality_cat.mean()])\n",
    "\n",
    "    init_impurity = gini_impurity(p)\n",
    "\n",
    "    G = []\n",
    "    t_range = np.linspace(df_wine.alcohol.min(), df_wine.alcohol.max(), 100)\n",
    "\n",
    "    for t in t_range:\n",
    "        idx = df_wine.alcohol < t\n",
    "        p1 = np.array([df_wine.loc[idx, 'quality_cat'].mean(), 1-df_wine.loc[idx, 'quality_cat'].mean()])\n",
    "        p2 = np.array([df_wine.loc[~idx, 'quality_cat'].mean(), 1-df_wine.loc[~idx, 'quality_cat'].mean()])\n",
    "\n",
    "        G.append(init_impurity - (idx.mean()*gini_impurity(p1) + (1-idx.mean())*gini_impurity(p2)))\n",
    "\n",
    "    ax[1].plot(t_range, G)\n",
    "    ax[1].set_xlabel('alcohol')\n",
    "    ax[1].set_ylabel('Gain')\n",
    "\n",
    "    mG = np.nanmax(G)\n",
    "    mt = t_range[np.nanargmax(G)]\n",
    "\n",
    "    ax[0].vlines(mt, 0, 150, label='best threshold (%.2f)' % mt)\n",
    "    ax[1].vlines(mt, 0, mG, label='best threshold\\n(gain = %.4f)' % mG)\n",
    "    \n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "wine_demo() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from ipywidgets import interact, IntSlider\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def demo_dec_tree(depth=1):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    C = np.array([[0., -0.7], [1.5, 0.7]])\n",
    "    gauss1 = np.dot(np.random.randn(200, 2) + np.array([4, 2]), C)\n",
    "    gauss2 = np.dot(np.random.randn(300, 2), C)\n",
    "\n",
    "    X = np.vstack([gauss1, gauss2])\n",
    "    y = np.r_[np.ones(200), np.zeros(300)]\n",
    "\n",
    "    ax[1].scatter(X[:,0], X[:, 1], c=y)\n",
    "    ax[1].set_xlabel('$x_1$')\n",
    "    ax[1].set_ylabel('$x_2$')\n",
    "\n",
    "    # Dec Tree Stuff\n",
    "    tree = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=123)\n",
    "    tree.fit(X,y)\n",
    "\n",
    "    x_range = np.linspace(X.min(), X.max(), 100)\n",
    "    xx1, xx2 = np.meshgrid(x_range, x_range)\n",
    "\n",
    "    Y = tree.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "    Y = Y.reshape(xx1.shape)\n",
    "\n",
    "    ax[1].contourf(xx1, xx2, Y, alpha=0.3)\n",
    "    ax[1].scatter(X[:,0], X[:,1],c=y)\n",
    "    \n",
    "#     dot_data = StringIO()  \n",
    "#     tree.export_graphviz(tree, out_file=dot_data,  \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "#     graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "#     ax[0].imshow(graph[0].create_png())\n",
    "\n",
    "\n",
    "    with open('tree.dot', 'w') as fout:\n",
    "        export_graphviz(tree, out_file=fout, feature_names=['x1', 'x2'], class_names=['0', '1'])\n",
    "    command = [\"dot\", \"-Tpng\", \"tree.dot\", \"-o\", \"tree.png\"]\n",
    "    subprocess.check_call(command)\n",
    "    ax[0].imshow(plt.imread('tree.png'))\n",
    "    ax[0].axis(\"off\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    fig = interact(demo_dec_tree, depth=IntSlider(min=1, max=5, value=1))\n",
    "except:\n",
    "    print('Что-то не так. Посмотрите на доску')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Как определяется ответ?\n",
    "\n",
    "* Классификация\n",
    "    * Класс с большинством в листе\n",
    "    * Доли каждого из классов в листе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Важность признаков\n",
    "\n",
    "В деревьях решений производится автоматический отбор признаков.\n",
    "\n",
    "Пусть $v(S)$ - это признак, который использовался для ветвления в узле $S$\n",
    "\n",
    "$$ \\text{imp}(A) = \\sum\\limits_{i: v(S_i) = A} \\frac{|S_i|}{|S|} Gain(S_i, A) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Работа с пропусками\n",
    "\n",
    "1. Удалить объекты\\признаки с пропусками\n",
    "2. Пропущенное значение = отдельная категория\n",
    "3. Surrogate split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Специальные алгоритмы построения деревьев\n",
    " \n",
    " \n",
    "** ID 3 **\n",
    "* Только категориальные признаки\n",
    "* Количество потомков = количеству значений признака\n",
    "* Строится до максимальной глубины\n",
    "\n",
    "** С 4.5 **\n",
    "* Поддержка вещественных признаков\n",
    "* Категриальные как в ID3\n",
    "* При пропуске значения переход по всем потомкам\n",
    "* Удаляет избыточные ветвления\n",
    "\n",
    "** СART **\n",
    "* В основном сегодняшнее занятие про него\n",
    "* Специальная процедура усещения дерева после построения (post prunning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Преимущества / Недостатки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "** Преимущества **\n",
    "* Простота построения\n",
    "* Интерпретируемость (при небольшой глубине)\n",
    "* Требуются минимальная предобработка признаков\n",
    "* Встроенный отбор признаков\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Недостатки **\n",
    "* Границы строяется только параллельно или перпендикулярно осям\n",
    "* При изменении набора данных надо полностью перестраивать и результат может получится совершенно иным\n",
    "* Жадность построения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://www.r2d3.us/visual-intro-to-machine-learning-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные с оттоком клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные об оттоке клиентов через pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('data/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df_init):\n",
    "    df_preproc = df_init.copy()\n",
    "    \n",
    "    # Удалили признаки\n",
    "    df_preproc = df_preproc.drop(['State', 'Area Code', 'Phone'], axis=1)\n",
    "    \n",
    "    # Замена категориальных признаков\n",
    "    df_preproc.loc[:,  [\"Int'l Plan\", 'VMail Plan']] = \\\n",
    "    df_preproc.loc[:,  [\"Int'l Plan\", 'VMail Plan']].replace({'no': 0, 'yes': 1})\n",
    "    \n",
    "    df_preproc.loc[:,  'Churn?'] = df_preproc.loc[:,  'Churn?'].replace({'False.': 0,\n",
    "                                                                         'True.': 1})\n",
    "    return df_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = df_churn.pipe(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_preproc.iloc[:, :-1].values, df_preproc.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация по одному гиперпараметру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что делает функция `validation_curve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import validation_curve\n",
    "except ImportError:\n",
    "    from sklearn.learning_curve import validation_curve\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`validation_curve` позволяе исследовать влияние отдельного гиперпараметра модели на ее качество.\n",
    "\n",
    "Построим валидационные кривые по гиперпараметру глубина дерева (`max_depth`) остальных гиперпараметрах, зафиксированных на значениях по-умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=132)\n",
    "\n",
    "train_scores, valid_scores = validation_curve(model, X, y, \n",
    "                                              'max_depth', range(1, 10),\n",
    "                                              cv=cv, scoring='roc_auc')\n",
    "# это значит, что мы будем проверять влияние параметра max_depth\n",
    "# в дапозоне от 1 до 10\n",
    "# и для этого мы будем использовать 5-fold кросс-валидацию\n",
    "# с мерой качества mean_absolute_error.\n",
    "# neg_ потому что по умолчанию в sklearn чем значение меры выше - тем лучше, \n",
    "# но в нашем случае нам нужно как раз допускать меньшую ошибку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите, что изображает синяя и красная линия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_mean = train_scores.mean(axis=1)\n",
    "train_score_std = train_scores.std(axis=1)\n",
    "valid_scores_mean = valid_scores.mean(axis=1)\n",
    "valid_scores_std = valid_scores.std(axis=1)\n",
    "\n",
    "plt.fill_between(range(1,10), train_score_mean-train_score_std, train_score_mean+train_score_std, color='b',\n",
    "                 interpolate=True, alpha=0.5,)\n",
    "plt.fill_between(range(1,10), valid_scores_mean-valid_scores_std, valid_scores_mean+valid_scores_std, color='r', \n",
    "                 interpolate=True, alpha=0.5)\n",
    "\n",
    "plt.plot(range(1,10), train_score_mean, c='b', lw=2)\n",
    "plt.plot(range(1,10), valid_scores_mean, c='r', lw=2)\n",
    "\n",
    "plt.xlabel('max depth')\n",
    "plt.ylabel('ROC AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор всех гиперпараметров\n",
    "\n",
    "Обычно подбирают гиперпараметры целыми группами. Есть несколько способов это делать\n",
    "* Полный перебор (Grid Search) - явно задаются все возможные значения параметров. Далее перебираются все возможные комбинации этих параметров\n",
    "* Случайный перебор (Random Search) - для некоотрых параметров задается распределение через функцию распределения. Задается количество случайных комбинаций, которых требуется перебрать.\n",
    "* \"Умный\" перебор ([hyperopt](http://hyperopt.github.io/hyperopt/)) - после каждого шага, следующия комбинация выбирается специальным образом, чтобы с одной стороны проверить неисследованные области, а с другой минимизировать функцию потерь. Не всегда работат так хорошо, как звучит.\n",
    "\n",
    "Мы же попробует случайный поиск. Почему случайный поиск лучше перебора:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='https://cdn-images-1.medium.com/max/800/1*ZTlQm_WRcrNqL-nLnx6GJA.png'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import GridSearchCV\n",
    "    from sklearn.cross_validation import RandomizedSearchCV\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "RND_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим пространство поиска\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(2, 8),\n",
    "    'min_samples_leaf': randint(5, 10),\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "# Некоторые параметры мы задали не простым перечислением значений, а \n",
    "# с помощью распределений.\n",
    "\n",
    "# Будем делать 200 запусков поиска\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=123)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=200, n_jobs=-1,\n",
    "                                   cv=cv, scoring='roc_auc', random_state=123)\n",
    "# А дальше, просто .fit()\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все прогоны. \n",
    "p = random_search.grid_scores_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем лучшую модель и выведем важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = random_search.best_estimator_\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое число соответствует важности признака, который подавался на вход\n",
    "\n",
    "Для каждого признака (с названием) получите его значение важности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = StringIO()  \n",
    "# tree.export_graphviz(model, out_file=dot_data, feature_names=feature_names, class_names=['0', '1'], \n",
    "#                    filled=True, rounded=True,  special_characters=True)  \n",
    "# graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph[0].create_png())\n",
    "\n",
    "with open('tree.dot', 'w') as fout:\n",
    "    export_graphviz(model, out_file=fout, feature_names=feature_names, class_names=['0', '1'], \n",
    "                   filled=True, rounded=True,  special_characters=True)\n",
    "command = [\"dot\", \"-Tpng\", \"tree.dot\", \"-o\", \"tree.png\"]\n",
    "subprocess.check_call(command)\n",
    "plt.imshow(plt.imread('tree.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Дополнительная информация:\n",
    "\n",
    "[Data Mining and Analysis: Fundamental Concepts and Algorithms](https://repo.palkeo.com/algo/information-retrieval/Data%20mining%20and%20analysis.pdf) Ch 18"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "291px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
