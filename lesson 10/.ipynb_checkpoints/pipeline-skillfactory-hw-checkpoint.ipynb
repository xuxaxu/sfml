{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Skillfactory---Практический-Machine-Learning\" data-toc-modified-id=\"Skillfactory---Практический-Machine-Learning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Skillfactory - Практический Machine Learning</a></div><div class=\"lev2 toc-item\"><a href=\"#19/02/2018---Аномалии,-работа-с-признаками,-пайплайны-(практика)\" data-toc-modified-id=\"19/02/2018---Аномалии,-работа-с-признаками,-пайплайны-(практика)-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>19/02/2018 - Аномалии, работа с признаками, пайплайны (практика)</a></div><div class=\"lev1 toc-item\"><a href=\"#Создание-пайплайна-и-генерация-признаков\" data-toc-modified-id=\"Создание-пайплайна-и-генерация-признаков-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Создание пайплайна и генерация признаков</a></div><div class=\"lev2 toc-item\"><a href=\"#Посмотрим-на-данные\" data-toc-modified-id=\"Посмотрим-на-данные-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Посмотрим на данные</a></div><div class=\"lev2 toc-item\"><a href=\"#Генерим-признаки\" data-toc-modified-id=\"Генерим-признаки-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Генерим признаки</a></div><div class=\"lev2 toc-item\"><a href=\"#Подбор-гипер-параметров\" data-toc-modified-id=\"Подбор-гипер-параметров-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Подбор гипер-параметров</a></div><div class=\"lev3 toc-item\"><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Pipeline</a></div><div class=\"lev3 toc-item\"><a href=\"#Подбор-гиперпараметров\" data-toc-modified-id=\"Подбор-гиперпараметров-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Подбор гиперпараметров</a></div><div class=\"lev4 toc-item\"><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-2321\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>Grid search</a></div><div class=\"lev4 toc-item\"><a href=\"#Random-Search\" data-toc-modified-id=\"Random-Search-2322\"><span class=\"toc-item-num\">2.3.2.2&nbsp;&nbsp;</span>Random Search</a></div><div class=\"lev3 toc-item\"><a href=\"#HyperOpt\" data-toc-modified-id=\"HyperOpt-233\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>HyperOpt</a></div><div class=\"lev2 toc-item\"><a href=\"#Ваш-черед\" data-toc-modified-id=\"Ваш-черед-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Ваш черед</a></div><div class=\"lev3 toc-item\"><a href=\"#Новые-признаки\" data-toc-modified-id=\"Новые-признаки-241\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Новые признаки</a></div><div class=\"lev2 toc-item\"><a href=\"#Поиск-гиперпараметров\" data-toc-modified-id=\"Поиск-гиперпараметров-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Поиск гиперпараметров</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skillfactory - Практический Machine Learning\n",
    "## 19/02/2018 - Аномалии, работа с признаками, пайплайны (практика)\n",
    "\n",
    "<center> Шестаков Андрей </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание пайплайна и генерация признаков\n",
    "<center>Шестаков Андрей</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы рассмотрим данные с предыдущего Sberbank Data Science Contest. К сожалению найти страницу с конкурсом уже не получается.\n",
    "\n",
    "Одной из задач была опредление пола владельца карты по его транзакциям на карте. Зачем это нужно - одному сберу известно, но эта задача была хороша тем, что в ней можно нагенерировать много разных признаков\n",
    "\n",
    "Есть такая [презентация](https://alexanderdyakonov.files.wordpress.com/2016/10/dj2016_sdsj_vis.pdf) с предварительным анализом данных и идеями про признаки\n",
    "\n",
    "Нам понадобятся файлы `customers_gender_train.csv`, `transactions.tsv.gz`, `mcc_types.tsv` и `trans_types.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это метки ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender = pd.read_csv('data/customers_gender_train.csv')\n",
    "df_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это сами транзакции (отрицательные транзакции - списывание, положительные - зачисление на счет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = pd.read_csv('data/transactions.csv.gz')\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, расшифровки кодов [mcc](https://ru.wikipedia.org/wiki/Merchant_Category_Code) и транзакций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('data/tr_types.csv', sep=';')\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcc = pd.read_csv('data/tr_mcc_codes.csv', sep=';')\n",
    "df_mcc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое что мы видем - это странная дата и суммы в транзакциях. \n",
    "\n",
    "В принципе, посмотрев на исходное распределение \"относительных\" дат по какой-нибудь гендерной группы mcc, становится примерно понятно, что за даты закодированы.\n",
    "\n",
    "Ну а суммы транзакций организаторы просто умножили на $\\pi^{\\exp}$ =)\n",
    "\n",
    "Преобразование будет проделано ниже, но при желании, можете сами со всем разобраться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Timestamp, DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc_transactions(df_transactions):\n",
    "    sec_per_day = 86400\n",
    "    sec_per_hour = 3600\n",
    "    \n",
    "    start_date = 1420070400 - 154 * sec_per_day - 3 * sec_per_hour\n",
    "    \n",
    "    df_transactions.loc[:, 'day'] = df_transactions.tr_datetime\\\n",
    "                                               .str.split(' ')\\\n",
    "                                               .str.get(0)\\\n",
    "                                               .astype(int)\n",
    "    df_transactions.loc[:, 'time_raw'] = df_transactions.tr_datetime\\\n",
    "                                                    .str.split(' ')\\\n",
    "                                                    .str.get(1)\n",
    "\n",
    "    # set temp dt\n",
    "    df_transactions.loc[:, 'dt_temp'] = pd.to_datetime(df_transactions.loc[:, 'time_raw'], \n",
    "                                                    format='%H:%M:%S')\\\n",
    "                                        + DateOffset(years=115)\n",
    "    \n",
    "    df_transactions = df_transactions.assign(dt = lambda x: x.dt_temp.astype(np.int64) // 10**9\n",
    "                                             + (x.day - 153) * sec_per_day)\\\n",
    "                                     .assign(weekday = lambda x: ((x.day + 4) % 7 + 1))\n",
    "        \n",
    "    df_transactions.loc[:, 'datetime'] = pd.to_datetime(df_transactions.dt, unit='s')\n",
    "    df_transactions.loc[:, 'date'] = df_transactions.loc[:, 'datetime'].dt.strftime('%Y-%m-%d')\n",
    "    df_transactions.loc[:, 'hour'] = df_transactions.loc[:, 'datetime'].dt.strftime('%H')\n",
    "    \n",
    "    df_transactions = df_transactions.drop(['dt_temp', 'time_raw', 'tr_datetime'], axis=1)\n",
    "    \n",
    "    df_transactions.loc[:, 'amount'] = np.round(df_transactions.loc[:, 'amount']/(np.pi**np.exp(1)))\n",
    "            \n",
    "    return df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = df_transactions.pipe(preproc_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерим признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве базовых признаков, можно взять, например, \n",
    "* количество (доля) транзакций по каждому mcc_code\n",
    "* количество (доля) транзакций в разные промежутки времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_features(df_gender, df_transactions):\n",
    "    \n",
    "    df_mcc_counts = \\\n",
    "        df_transactions.pivot_table(index=['customer_id'], columns='mcc_code', values='amount', \n",
    "                             aggfunc=np.size, fill_value=0)\n",
    "\n",
    "    df_mcc_counts = df_mcc_counts.rename_axis(lambda x: 'mcc_{}_count'.format(x), axis=1)\n",
    "\n",
    "    df_hour_rations = \\\n",
    "        df_transactions.pivot_table(index=['customer_id'], columns='hour', values='amount', \n",
    "                             aggfunc=np.size, fill_value=0)\n",
    "\n",
    "    # Сложная и нетривиальная конструкция\n",
    "    total = df_hour_rations.sum(axis=1)\n",
    "    df_hour_rations.loc[:, 'morning'] = (df_hour_counts.loc[:, '05':'11'].sum(axis=1).T/total).T\n",
    "    df_hour_rations.loc[:, 'day'] = (df_hour_counts.loc[:, '12':'17'].sum(axis=1).T/total).T\n",
    "    df_hour_rations.loc[:, 'evening'] = (df_hour_counts.loc[:, '18':'23'].sum(axis=1).T/total).T\n",
    "    df_hour_rations.loc[:, 'night'] = (df_hour_counts.loc[:, '00':'04'].sum(axis=1).T/total).T\n",
    "\n",
    "\n",
    "    # Объединяем:\n",
    "    df_features = df_gender.join(df_mcc_counts, on='customer_id', how='left')\\\n",
    "                           .join(df_hour_rations.loc[:, ['morning', 'day', 'evening', 'night']], on='customer_id', how='left')\n",
    "        \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_gender.pipe(gen_features, df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = 'gender'\n",
    "idx_features = df_features.columns != label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.loc[:, idx_features].values\n",
    "y = df_features.loc[:, ~idx_features].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гипер-параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем простой sklearn пайплайн, который делает следующее:\n",
    "* Нормирует признаки через StandartScaler\n",
    "* Запускает лог-регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND_SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров\n",
    "\n",
    "До этого мы исключительно смотрели, как влияет на меру качества какой-то один параметр при фиксированных остальных. Пришло время перебирать все что можно!\n",
    "\n",
    "В базовом варианте, это делается либо через `Grid Search`, либо через `Random Search`. Какие ключевые отличия?\n",
    "* В `Grid Search` вы в явнов виде задаете возможные значения каждого гипер-параметра, который хотите варьировать. Соответственно, выполняется **полный** перебор всех возможных комбинаций\n",
    "* В `Random Search` допукается указание распределения параметров, например \"равномерно, на интервале от 0 до 100\" или \"нормальное распределение с таким-то цетром и такой-то дисперсией. Соответственно, так как это случайный перебор, то **вы** просто **задаете** количество случайных комбинаций, которые будут проверяться\n",
    "\n",
    "Может показаться, что делать случайный перебор опасно - там же все случайно. Но на практике именно он и искользуется в силу двух причин\n",
    "* Полный перебор большого количества комбинаций очень долгий\n",
    "* Мы можем просто пропустить значения гиперпараметра, которые сильно влияют на метрику качества (см рисунок снизу)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/gridsearch.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оба варианта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем значения параметров, которые хотим проверить\n",
    "\n",
    "# в данном случае \"__\" разленяет название гиперпараметра от этапа, где этот гиперпараметр используется\n",
    "# если у нас будет не пайплайн, а просто один классификатор, то разделитель указывать не нужно\n",
    "param_grid = {\n",
    "    'scaler__with_mean': [False, True],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__random_state': [RND_SEED],\n",
    "    'clf__C': np.logspace(-5, 3, 10)\n",
    "}\n",
    "\n",
    "print(param_grid)\n",
    "\n",
    "# Задаем схему кросс-валидации\n",
    "cv = StratifiedKFold(n_splits=5, random_state=RND_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_searcher = GridSearchCV(model, param_grid, \n",
    "                             scoring='roc_auc', \n",
    "                             n_jobs=-1, cv=cv, \n",
    "                             verbose=2)\n",
    "\n",
    "grid_searcher.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе в grid_searcher можно посмотреть, какая комбинация оказалась наилучшей, сколько занял рачет и напрямую достать лучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_searcher.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = grid_searcher.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import lognorm as sp_lognorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_lognorm(4).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем значения параметров, которые хотим проверить\n",
    "# Теперь с распределениями\n",
    "param_grid = {\n",
    "    'scaler__with_mean': [False, True],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__random_state': [RND_SEED],\n",
    "    'clf__C': sp_lognorm(4)\n",
    "}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Рассмотрим 20 случайных комбинаций\n",
    "random_searcher = RandomizedSearchCV(model, param_grid, n_iter=20, \n",
    "                                     random_state=RND_SEED,\n",
    "                                     scoring='roc_auc', \n",
    "                                     n_jobs=-1, cv=cv, \n",
    "                                     verbose=2)\n",
    "\n",
    "random_searcher.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичный выхлоп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(random_searcher.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = random_searcher.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть еще другой вариант - \"умный\" перебор параметров. И вот тут нам помогает библиотека `hyperopt`.\n",
    "\n",
    "Если невдаваться в детали, то `hyperopt` определяет следующего набора-кандидата с помощью некоторого алгоритма, который балансирует исследование еще не изведанных областей значений гиперпараметров и направления, вдоль которых наблюдались улучшения целеой метрики.\n",
    "\n",
    "То есть мы задаем некоторую функцию, и ставим себе цель **минимизировать** (такова договоренность в `hyperopt`) ее значение исходя из параметров, которые она принимает.\n",
    "\n",
    "Например, возьмем функцию $f(x) = \\sin(x)/x$ и будем искать ее минимум при условии, что $x$ будет равномерно распределен на интервале $[-7.5, 7.5]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sudo pip install networkx==1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=lambda x: -np.sin(x)/x,\n",
    "    space=hp.uniform('x', -7.5, 7.5),\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials)\n",
    "\n",
    "print best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,50)\n",
    "func = lambda x: -np.sin(x)/x\n",
    "y = func(x)\n",
    "plt.plot(x,y)\n",
    "\n",
    "y_best = func(best['x'])\n",
    "plt.plot(best['x'], y_best, marker='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нашли)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возвращаясь к нашим баранам, функция вданном случае будет возвращать метрику качества модели (пайплайна) на кроссвалидации. С помощью `hyperopt` мы будем искать минимум этой функции при заданных диаполознах значений гипер параметров.\n",
    "\n",
    "Но самым важным плюсом, как по мне, является гибкость - в функцию, которую мы хотим минимизировать можно написать все что угодно. Например, сейчас я добавлю вариативность в пайплайне по типу шкалирования между - StandartScaler или RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.loc[:, idx_features].values\n",
    "y = df_features.loc[:, ~idx_features].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_trials_template(X, y, params, evals=100):\n",
    "\n",
    "    def hyperopt_cv(X, y, params):\n",
    "        \n",
    "        X_ = X.copy()\n",
    "        \n",
    "        # Отделяем параметры лог регрессии в отдельный словарь\n",
    "        lm_params = {}\n",
    "        for k, v in params.iteritems():\n",
    "            if k.startswith('glob'):\n",
    "                continue                \n",
    "            elif k.startswith('lm'):\n",
    "                lm_params[k.split('_', 1)[1]] = v\n",
    "        \n",
    "        # Задаем шкалирование\n",
    "        if params['scaler_type'] == 'standart':\n",
    "            scaler = StandardScaler(with_mean=params['scaler_centering'])\n",
    "        else:\n",
    "            assert params['scaler_type'] == 'robust'\n",
    "            scaler = RobustScaler(with_centering=params['scaler_centering'])\n",
    "        \n",
    "        # Создаем лог рег с нужными параметрами\n",
    "        clf = LogisticRegression(**lm_params)\n",
    "        \n",
    "        # Итоговый пайплайн\n",
    "        model = Pipeline([\n",
    "            ('scaler', scaler),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "\n",
    "        # Схема кросс-валидации\n",
    "        n_splits = 5\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, \n",
    "                             random_state=RND_SEED)\n",
    "        scores = cross_val_score(model, X_, y,\n",
    "                                 scoring='roc_auc', \n",
    "                                 cv=cv, \n",
    "                                 n_jobs=-1)\n",
    "\n",
    "        # Возвращаем среднее значение метрики и отклонение (на всякий случай)\n",
    "        return scores.mean(), scores.std()\n",
    "\n",
    "    def f(params):\n",
    "        acc, std = hyperopt_cv(X, y, params)\n",
    "        return {'loss': -acc, 'qscore': -acc, 'qscore_std': std, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(f, \n",
    "                params, \n",
    "                algo=tpe.suggest, \n",
    "                max_evals=evals, \n",
    "                trials=trials, \n",
    "                verbose=1)\n",
    "    \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем пространство поиска\n",
    "space4_lm = {\n",
    "    'lm_penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'lm_C': hp.loguniform('C', -5, 3),\n",
    "    'lm_class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'lm_random_state': RND_SEED,\n",
    "    'scaler_type': hp.choice('scaler_type', ['standart', 'robust']),\n",
    "    'scaler_centering': hp.choice('scaler_centering', [False, True])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запускаем поиск\n",
    "trials = run_trials_template(X, y, space4_lm, evals=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trials_df(trials):\n",
    "    '''\n",
    "    Функция форматирует результаты hyperopt в dataframe\n",
    "    '''\n",
    "    tr_dict = []\n",
    "    for t in trials:\n",
    "        trial = dict()\n",
    "        for k, v in t['misc']['vals'].iteritems():\n",
    "            trial[k] = v[0]\n",
    "\n",
    "        trial['qscore'] = -t['result']['qscore']\n",
    "        trial['qscore_std'] = -t['result']['qscore_std']\n",
    "        tr_dict.append(trial)\n",
    "\n",
    "    df_res = pd.DataFrame.from_dict(tr_dict)\n",
    "    df_res = df_res.sort_values('qscore', ascending=False)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаем результаты.\n",
    "\n",
    "Стоит оговорится, что в некоторых столбцах указаны не фактические значение гиперпараметров, а их позиция в соответствуюем поле в `space4_lm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trials = trials_df(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь `qscore` - метрика качесва, а `scaler_type = 1` означает, что был выбран `scaler_type = robust`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ваш черед"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Новые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание творческое - придумайте по новому признаку (группе признаков)\n",
    "* На основе mcc (tr_type)\n",
    "* На основе временного фактора\n",
    "* На основе текстов из описания mcc\n",
    "\n",
    "Реалиуйте их в функции, аналогичной `gen_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию для hyperopt по перебору гипер параметров вашего пайплайна\n",
    "\n",
    "На всякий случай почитайте еще про [`FeatureUnion`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) и [пример](http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html#sphx-glr-auto-examples-hetero-feature-union-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# А это трансформер, который выбирает подможнество столбцов из матрицы X\n",
    "# Который нужен для того, чтобы делать какие-то действия только для подмноества столбцов, а потом объединять результаты\n",
    "# Через FeatureUnion\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_idx):\n",
    "        self.col_idx = col_idx\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.col_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "347px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "222px",
    "left": "0px",
    "right": "1247.33px",
    "top": "108px",
    "width": "182px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "40px",
   "left": "816px",
   "right": "38.6667px",
   "top": "0px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
